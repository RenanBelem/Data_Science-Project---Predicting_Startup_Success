# üöÄ Predicting Startup Success: Data Science & Machine Learning

> **Projeto de Ci√™ncia de Dados - PUCPR** \>

Este reposit√≥rio cont√©m o c√≥digo, apresenta√ß√µes e documenta√ß√£o de um projeto completo de Ci√™ncia de Dados focado na previs√£o do sucesso de startups. O objetivo √© utilizar dados hist√≥ricos para classificar se uma startup ser√° **adquirida** (*acquired*) ou **fechada** (*closed*).

## üë• Autores (Equipe 4)

  * Guilherme Schwarz
  * J√∫lia Cristina Moreira da Silva
  * Matheus Francisco Trevisan Del Zotto
  * Renan Belem Biavati

-----

## üìÇ Estrutura do Projeto

O projeto foi dividido em duas grandes etapas:

### 1\. Etapa de Checkpoint (An√°lise Explorat√≥ria)

Foco no entendimento dos dados, limpeza inicial e valida√ß√£o de hip√≥teses de neg√≥cio.

  * **Arquivos:** `project_checkpoint.ipynb`, `checkpoint_presentation.pdf`
  * **Atividades:**
      * Carregamento e limpeza do dataset (`startup data.csv`).
      * An√°lise Univariada (distribui√ß√µes, assimetria, curtose).
      * An√°lise Multivariada e teste de hip√≥teses (ex: impacto de crises econ√¥micas, financiamento por setor).
      * Engenharia de Atributos inicial (cria√ß√£o de `is_technology`, `age_at_closing`).

### 2\. Etapa Final (Modelagem Preditiva)

Foco na constru√ß√£o de pipelines de Machine Learning, balanceamento de classes e sele√ß√£o de atributos para maximizar m√©tricas de classifica√ß√£o.

  * **Arquivos:** `final_project.ipynb`, `final_project_presentation.pdf`, `project_manuscript.pdf`
  * **Atividades:**
      * Pr√©-processamento avan√ßado e *encoding*.
      * Implementa√ß√£o de Pipelines com `imblearn`.
      * Compara√ß√£o de 19 combina√ß√µes de modelos, seletores de \<em\>features\</em\> e balanceadores.
      * Valida√ß√£o Cruzada (*Stratified K-Fold*).

-----

## üìä Sobre o Dataset

O conjunto de dados (`startup data.csv`) cont√©m informa√ß√µes sobre aproximadamente **923 startups** norte-americanas fundadas entre 1998 e 2013.

  * **Target:** `status` (Bin√°rio: `acquired` ou `closed`).
  * **Desbalanceamento:** \~64.7% Acquired vs \~35.3% Closed.
  * **Atributos Principais:**
      * **Num√©ricos:** `funding_total_usd`, `milestones`, `relationships`, `age_at_closing`.
      * **Categ√≥ricos:** `state_code`, `category_code`, `is_CA` (Calif√≥rnia), `is_NY` (Nova Iorque).
      * **Temporais:** Datas de funda√ß√£o, primeiro financiamento e encerramento.

-----

## üõ†Ô∏è Metodologia e Tecnologias

O projeto utilizou **Python** e as bibliotecas `pandas`, `seaborn`, `matplotlib`, `scikit-learn` e `imblearn`.

### Pipelines de Machine Learning

Para garantir a robustez e evitar *data leakage*, foram testadas combina√ß√µes automatizadas de:

1.  **Balanceamento de Classes:**
      * `RandomUnderSampler` (RUS)
      * `SMOTE` (Oversampling)
2.  **Sele√ß√£o de Atributos:**
      * `PCA` (Principal Component Analysis)
      * `RFE` (Recursive Feature Elimination)
      * `SelectKBest` (Univariado)
3.  **Modelos de Classifica√ß√£o:**
      * Random Forest
      * Gradient Boosting
      * Logistic Regression
      * Support Vector Machine (SVM)
      * K-Nearest Neighbors (KNN)

### M√©tricas de Avalia√ß√£o

Devido ao desbalanceamento das classes, a m√©trica principal de decis√£o foi o **F1-Score (Weighted)**, apoiada por Acur√°cia, Precis√£o, Recall e Tempo de Execu√ß√£o.

-----

## üìà Principais Resultados e Insights

### Descobertas da An√°lise Explorat√≥ria (EDA)

  * **Impacto de Crises:** Houve um aumento significativo no fechamento de startups nos anos seguintes √† crise de 2008.
  * **Tech vs Non-Tech:** Empresas de tecnologia recebem, em m√©dia, mais financiamento que as de outros setores.
  * **Marcos Iniciais:** Atingir o primeiro marco (*milestone*) cedo n√£o mostrou correla√ß√£o forte com o sucesso final da empresa.

### Desempenho dos Modelos

A tabela abaixo resume os melhores e piores desempenhos encontrados nos experimentos:

| Modelo | Balanceamento | Sele√ß√£o | F1-Score | Tempo (s) | Observa√ß√£o |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Random Forest** | SMOTE | RFE | **0.99** | 805s | Alto custo computacional |
| **Log. Regression**| RandomUnderSampler| SelectKBest | **0.99** | **0.63s** | **Melhor Custo-Benef√≠cio** |
| SVM | RandomUnderSampler| PCA | 0.81 | 1.16s | PCA prejudicou o desempenho |
| KNN | SMOTE | PCA | 0.78 | 1.06s | Pior combina√ß√£o |

> **Conclus√£o:** O uso de **PCA reduziu o desempenho** em quase todos os cen√°rios, indicando que a interpretabilidade e a vari√¢ncia original das *features* eram cruciais. Pipelines mais simples (Regress√£o Log√≠stica + SelectKBest) atingiram resultados de estado-da-arte com fra√ß√£o do custo computacional de modelos complexos (como Gradient Boosting + RFE).

-----

## üîß Como Executar

1.  **Pr√©-requisitos:**
    Certifique-se de ter instalado as bibliotecas listadas no in√≠cio dos notebooks:

    ```bash
    pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn
    ```

2.  **Arquivos:**

      * Coloque o arquivo `startup data.csv` no mesmo diret√≥rio dos notebooks.
      * Execute o `final_project.ipynb` para reproduzir o pipeline de Machine Learning completo.
      * Execute o `project_checkpoint.ipynb` para visualizar a an√°lise explorat√≥ria e os gr√°ficos iniciais.

-----

## üìÑ Conte√∫do dos Arquivos

  * `project_manuscript.pdf`: Artigo cient√≠fico completo formatado (IEEE style) descrevendo todo o projeto, fundamenta√ß√£o te√≥rica e discuss√£o aprofundada.
  * `checkpoint_presentation.pdf`: Slides apresentando a caracteriza√ß√£o do dataset e os insights visuais da primeira etapa.
  * `final_project_presentation.pdf`: Slides finais com a arquitetura dos pipelines, an√°lise comparativa dos modelos e conclus√µes.
  * `final_project.ipynb`: Notebook principal com o c√≥digo de treinamento, valida√ß√£o e teste dos modelos.
  * `project_checkpoint.ipynb`: Notebook com a limpeza de dados e gera√ß√£o dos gr√°ficos de EDA.
